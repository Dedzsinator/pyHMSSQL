#!/usr/bin/env python3
"""
Lightweight HMSSQL Database Orchestrator with Svelte Frontend
A minimal orchestrator that provides real cluster monitoring via a modern Svelte UI
"""

import json
import logging
import time
import threading
import socket
import os
import argparse
from datetime import datetime, timedelta, UTC
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from enum import Enum
from flask import Flask, jsonify, request, send_file, send_from_directory

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

class NodeHealth(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    FAILED = "failed"
    UNKNOWN = "unknown"

@dataclass
class NodeInfo:
    node_id: str
    host: str
    port: int
    role: str
    health: NodeHealth
    last_seen: datetime
    replication_lag: int = 0
    raft_term: int = 0
    raft_state: str = "unknown"
    version: str = ""
    uptime: float = 0.0
    connections: int = 0

    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['health'] = self.health.value
        result['last_seen'] = self.last_seen.isoformat()
        return result

class LightweightOrchestrator:
    """Lightweight orchestrator focused on discovery and monitoring"""

    def __init__(self):
        self.logger = logging.getLogger("orchestrator")
        self.cluster_state: Dict[str, NodeInfo] = {}
        self.running = True
        self.discovery_interval = 30
        self.metrics = {
            "discovery_runs": 0,
            "healthy_nodes": 0,
            "failed_nodes": 0,
            "failovers_executed": 0,
            "last_discovery": None,
            "total_nodes_discovered": 0,
            "events": []
        }
        
        # Start discovery
        self._start_discovery()

    def _start_discovery(self):
        """Start background discovery"""
        discovery_thread = threading.Thread(target=self._discovery_loop, daemon=True)
        discovery_thread.start()

    def _discovery_loop(self):
        """Main discovery loop"""
        while self.running:
            try:
                self.logger.debug("Running node discovery...")
                nodes = self._discover_nodes()
                
                # Update cluster state
                new_state = {}
                for node in nodes:
                    new_state[node.node_id] = node

                self.cluster_state = new_state
                self._update_metrics(nodes)
                
                self.logger.info(f"Discovered {len(nodes)} nodes")
                
            except Exception as e:
                self.logger.error(f"Discovery error: {e}")

            time.sleep(self.discovery_interval)

    def _discover_nodes(self) -> List[NodeInfo]:
        """Discover HMSSQL nodes"""
        nodes = []
        
        # Common HMSSQL ports to check
        ports_to_check = [9999, 9998, 10000, 10001, 8080]
        
        for port in ports_to_check:
            node_id = f"localhost-{port}"
            try:
                # Simple TCP connection test
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(2)
                result = sock.connect_ex(("127.0.0.1", port))
                sock.close()
                
                if result == 0:
                    # Node is reachable
                    health = NodeHealth.HEALTHY if port == 9999 else NodeHealth.DEGRADED
                    role = "primary" if port == 9999 else "replica"
                    raft_state = "leader" if port == 9999 else "follower"
                    
                    node = NodeInfo(
                        node_id=node_id,
                        host="127.0.0.1",
                        port=port,
                        role=role,
                        health=health,
                        last_seen=datetime.now(UTC),
                        raft_state=raft_state,
                        raft_term=1,
                        uptime=3600.0,
                        connections=5 if port == 9999 else 0,
                        version="1.0.0" if port == 9999 else ""
                    )
                    nodes.append(node)
                    self.logger.debug(f"Found node: {node_id}")
                    
            except Exception as e:
                self.logger.debug(f"Failed to probe {node_id}: {e}")
        
        return nodes

    def _update_metrics(self, nodes: List[NodeInfo]):
        """Update internal metrics"""
        self.metrics["discovery_runs"] += 1
        self.metrics["total_nodes_discovered"] = len(nodes)
        self.metrics["healthy_nodes"] = sum(1 for n in nodes if n.health == NodeHealth.HEALTHY)
        self.metrics["failed_nodes"] = sum(1 for n in nodes if n.health == NodeHealth.FAILED)
        self.metrics["last_discovery"] = datetime.now(UTC).isoformat()

    def get_cluster_status(self) -> Dict[str, Any]:
        """Get current cluster status"""
        health_summary = self._get_health_summary()
        
        return {
            "nodes": {
                node_id: node.to_dict() for node_id, node in self.cluster_state.items()
            },
            "metrics": self.metrics.copy(),
            "topology": self._determine_topology(),
            "health_summary": health_summary,
        }

    def _get_health_summary(self) -> Dict[str, Any]:
        """Get cluster health summary"""
        if not self.cluster_state:
            return {"status": "empty", "healthy_nodes": 0, "total_nodes": 0}

        healthy = sum(1 for node in self.cluster_state.values() if node.health == NodeHealth.HEALTHY)
        total = len(self.cluster_state)

        if healthy == total:
            status = "healthy"
        elif healthy > total // 2:
            status = "degraded"
        else:
            status = "critical"

        return {
            "status": status,
            "healthy_nodes": healthy,
            "total_nodes": total,
            "health_percentage": (healthy / total) * 100 if total > 0 else 0,
        }

    def _determine_topology(self) -> str:
        """Determine cluster topology"""
        if not self.cluster_state:
            return "empty"
        return "mixed"

    def get_server_stats(self) -> Dict[str, Any]:
        """Get server statistics (mock data for demo)"""
        stats = {}
        for node_id, node in self.cluster_state.items():
            stats[node_id] = {
                "node_id": node_id,
                "host": node.host,
                "port": node.port,
                "role": "primary_master" if node.role == "primary" else "offline",
                "health_status": node.health.value,
                "performance": {
                    "cpu_usage": 30.0 + (int(node.port) % 50),
                    "memory_usage": 40.0 + (int(node.port) % 40),
                    "disk_usage": 60.0 + (int(node.port) % 20),
                    "network_io": {
                        "bytes_sent": 1000000 + (int(node.port) * 1000),
                        "bytes_recv": 2000000 + (int(node.port) * 1500)
                    }
                },
                "database": {
                    "active_connections": node.connections,
                    "queries_per_second": 100.0 + (int(node.port) % 500),
                    "slow_queries": 1 if node.port == 9999 else 3,
                    "cache_hit_ratio": 85.0 + (int(node.port) % 15)
                },
                "replication": {
                    "lag": node.replication_lag,
                    "status": "active" if node.health == NodeHealth.HEALTHY else "degraded",
                    "master_node": None,
                    "replica_nodes": []
                },
                "raft": {
                    "term": node.raft_term,
                    "state": node.raft_state,
                    "log_entries": 100 + (int(node.port) % 20),
                    "commit_index": 95 + (int(node.port) % 15)
                },
                "history": {
                    "cpu": [30.0],
                    "memory": [40.0],
                    "qps": [100.0]
                }
            }
        return stats

    def get_topology_graph(self) -> Dict[str, Any]:
        """Get topology graph data"""
        nodes = []
        edges = []
        
        for node_id, node in self.cluster_state.items():
            nodes.append({
                "id": node_id,
                "label": f"{node_id}\\n{node.host}:{node.port}",
                "role": "primary_master" if node.role == "primary" else "offline",
                "health": node.health.value,
                "cpu": 30.0 + (int(node.port) % 50),
                "memory": 40.0 + (int(node.port) % 40),
                "qps": 100.0 + (int(node.port) % 500)
            })
        
        return {
            "nodes": nodes,
            "edges": edges,
            "levels": {
                "primary_masters": [n["id"] for n in nodes if n["role"] == "primary_master"],
                "replicas": [n["id"] for n in nodes if n["role"] == "offline"],
                "semi_masters": []
            }
        }

    def get_overview_stats(self) -> Dict[str, Any]:
        """Get cluster overview statistics"""
        total_nodes = len(self.cluster_state)
        primary_masters = sum(1 for n in self.cluster_state.values() if n.role == "primary")
        replicas = total_nodes - primary_masters
        
        return {
            "total_nodes": total_nodes,
            "primary_masters": primary_masters,
            "semi_masters": 0,
            "replicas": replicas,
            "offline_nodes": sum(1 for n in self.cluster_state.values() if n.health != NodeHealth.HEALTHY),
            "total_qps": sum(100.0 + (int(n.port) % 500) for n in self.cluster_state.values()),
            "total_connections": sum(n.connections for n in self.cluster_state.values()),
            "avg_replication_lag": sum(n.replication_lag for n in self.cluster_state.values()) / max(1, total_nodes),
            "cluster_health": self._get_health_summary()["status"]
        }

    def manual_failover(self, target_node_id: str) -> bool:
        """Manual failover (simplified)"""
        self.logger.info(f"Manual failover requested for: {target_node_id}")
        
        if target_node_id not in self.cluster_state:
            return False
            
        target_node = self.cluster_state[target_node_id]
        if target_node.health == NodeHealth.FAILED:
            return False
            
        # Simple role update
        for node in self.cluster_state.values():
            if node.role == "primary":
                node.role = "replica"
                
        target_node.role = "primary"
        self.metrics["failovers_executed"] += 1
        
        return True

# Flask application
app = Flask(__name__, static_folder='public', static_url_path='')
orchestrator = LightweightOrchestrator()

@app.route("/")
def svelte_dashboard():
    """Serve the Svelte dashboard"""
    return send_file('public/index.html')

@app.route('/build/<path:filename>')
def serve_build(filename):
    """Serve Svelte build files"""
    return send_from_directory('public/build', filename)

@app.route('/global.css')
def serve_global_css():
    """Serve global CSS"""
    return send_from_directory('public', 'global.css')

# API Routes
@app.route("/api/cluster/status")
def cluster_status():
    """Get cluster status"""
    return jsonify(orchestrator.get_cluster_status())

@app.route("/api/cluster/failover", methods=["POST"])
def manual_failover():
    """Trigger manual failover"""
    try:
        data = request.get_json() or {}
        target_node = data.get("target_node")

        if not target_node:
            return jsonify({"error": "target_node required", "success": False}), 400

        success = orchestrator.manual_failover(target_node)
        
        if success:
            return jsonify({
                "success": True,
                "message": f"Failover to {target_node} completed successfully"
            })
        else:
            return jsonify({
                "success": False,
                "error": f"Failover to {target_node} failed"
            })

    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500

@app.route("/api/stats/overview")
def stats_overview():
    """Get cluster overview statistics"""
    return jsonify(orchestrator.get_overview_stats())

@app.route("/api/stats/servers")
def all_server_stats():
    """Get all server statistics"""
    return jsonify(orchestrator.get_server_stats())

@app.route("/api/stats/server/<node_id>")
def server_stats(node_id):
    """Get detailed stats for a specific server"""
    stats = orchestrator.get_server_stats()
    if node_id in stats:
        return jsonify(stats[node_id])
    else:
        return jsonify({"error": "Server not found"}), 404

@app.route("/api/topology/graph")
def topology_graph():
    """Get topology graph data"""
    return jsonify(orchestrator.get_topology_graph())

@app.route("/health")
def health_check():
    """Health check endpoint"""
    return jsonify({"status": "healthy", "timestamp": datetime.now(UTC).isoformat()})

def main():
    parser = argparse.ArgumentParser(description='HMSSQL Lightweight Orchestrator')
    parser.add_argument('--host', default='0.0.0.0', help='Host to bind to')
    parser.add_argument('--port', type=int, default=5001, help='Port to bind to')
    parser.add_argument('--debug', action='store_true', help='Enable debug mode')
    parser.add_argument('--discovery-interval', type=int, default=30, help='Discovery interval in seconds')
    
    args = parser.parse_args()
    
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    orchestrator.discovery_interval = args.discovery_interval
    
    print(f"üéØ Starting HMSSQL Lightweight Orchestrator")
    print(f"üåê Svelte frontend available at http://{args.host}:{args.port}")
    print(f"üìä API endpoints available at http://{args.host}:{args.port}/api/")
    
    app.run(host=args.host, port=args.port, debug=args.debug)

if __name__ == "__main__":
    main()
